{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 텍스트 크롤링\n",
    "## 5.1 Beautifulsoup을 이용한 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\home\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\home\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\home\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=urlopen(\"http://www.naver.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 class=\"logo_default\">\n",
       "<a class=\"logo_naver\" data-clk=\"top.logo\" href=\"/\"><span class=\"blind\">네이버</span></a>\n",
       "</h1>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs0bj = BeautifulSoup(html.read(), \"html.parser\")\n",
    "bs0bj.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "List = bs0bj.findAll(\"span\",{\"class\":\"yellow\"})\n",
    "for i in List:\n",
    "    print(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 댓글 읽기\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import sys\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"이 어려운 시기에 세금을 어마어마하게 초과해서 걷었다면 그 돈으로 매연저감장치를 부착해주던지 실비로 폐차비용을 지불해 주던지 해야지 무조건 길을 못다니게 하면 되냐.. 이 깡패같은 정권아...그럼 디젤차에 환경부담금은 왜 걷는거냐 ?\"',\n",
       " '\"백령도 앞바다에 미센먼지 지랄같은것은 육지의 5등급차 운행제한걸면 해결도겟나?ㅋㅋㅋㅋ\\\\n원인 제공국에는 머라 찍소리 못하고...\"',\n",
       " '\"중국발 미세먼지 보다 더 두렵고 무서운건, 치명적인 발암물질인 미세먼지에 대해 일언반구 일절 언급도 없고 아무대책없이 한가하게 두손놓고 있는 문재앙의 인식과 태도이다 과연 일국의 대통인지 되묻지 않을수없다 !\"',\n",
       " '\"디젤차 환경부담금걷은거 다내놔\\\\n도대체 뭐하는거야\\\\n이건진짜 재앙이다\\\\n중국가서 기자들 졸라 맞아도 말한마디 못하고~\\\\n이 문등신~~\\\\n외국 나가서는OOO 그지짓 하고 다니고\\\\n저게 대통령이래\\\\n아고~~\\\\n울화통 터져\"',\n",
       " '\"얼마전 중국에서 유입된 미세먼지가 80%가 넘는다는 조사결과가 있었는데 어째서 자국민만 때려잡나요 중국에게 할말은 하겠다며 집권한 대통령은 또 어째서 꿀먹은 벙어리가 되셨는지요\"',\n",
       " '\"없는 사람이 좋은차 타겠나\\\\n누구는 안 바꾸고 싶겠나\\\\nㅅㅂ 없는것도 서러운데 ㅅㅈ하고 있네\"',\n",
       " '\"OECD국가중 석탄  재일 연료 많이쓰고 개발 수출하는 나라로 1위에 올랐다는야기 부끄러운줄알라구요  개뿔 이것들은 짱께에겐 한마디도 못하고 국민들만 들볶고있는 바보들\"',\n",
       " '\"괜란 서민들 잡지말고  중국이나 잡어라잉 중국은 무섭지 무역보복 할까봐 말한마디 쎄게 못하겠지\"',\n",
       " '\"중공에서  5억대분의 매연이 날아오는데    5등급차몇대운행중지가 무슨효과가 있을까.. ?\"',\n",
       " '\"일 정말 못한다\"',\n",
       " '\"또 뭐라고 짓거리는거야ㅡㅡ 하...정말 이제 지친다지처 적당히 세금쳐가져가고 일좀 똑바로하고 서민들 좀 건들지마라\"',\n",
       " '\"ㅎㅎㅎ 빛내서 차사라는거네... 참 조 오 ㅅ 간네 민초들 삶이 더 힘들어지네... 있는넘만 더 혜택보는 조가튼 개한민국\"',\n",
       " '\"OOO 원숭이 또 뻘짓하네 효과도 없는 전시행정만  하는후 원숭이새끼 지새끼도 못보고 사는 불쌍한 원숭이\"',\n",
       " '\"중국과 문재인 싹~다 갈겨버렸으면 좋겠다!! 스스로 인간이기를 포기한 쓰레기중의 쓰레기들!\"',\n",
       " '\"저감장치달면 뭐하냐 저감이 하나도 안되는데. DPF가 다 있으나마나 저감효과 하나도없다. 탁상행정해봐야 실정은 하나도 모르는 인간들. 차량만 통제하면 답이나오냐! 오전시간이 다들 영업용차량들은 바쁘게 일하는시간인데 다니지말라면 그냥 일그만두라는거냐 뭐냐! 그러면서 경유차 환경부담금은 왜 꼬박꼬박 걷어가는데? 그런데 쓰라고 세금낸거 아니냐! 중국짱개들한테나 항의해라.  애꾿은 서민들 못살게하지말고.\"',\n",
       " '\"환경부담금 자동차세 그돈 세금 다걷어가면서 그돈으론 개선하지도 않고 차는팔아재끼고 운행금지? 웃기는 나라군 매년 세금 풍년인나라 살기좆내ㅋㅋ\"',\n",
       " '\"민주당 문재인 찍은 제가 바보네요. 졸 후회 됩니다.\"',\n",
       " '\"서울시가 없는 서민 협박하네  돈 없어서 차 못바꿨다  어쩔래  이게 나라냐 시민을 단속으로 헙박하다니\"',\n",
       " '\"노후 경유차 운행하는 서민들이 밥이군, 진짜로 돈없어서 차량 교체 못하는 서민들은 화난다 ~~~~\"',\n",
       " '\"휴원이면 휴원이지 휴원권고는 뭐니? 결국 공무원 쉐리들은 조치 취했다고 욕 먹을거 피해가고 휴원을 해도 안해도 애꿎은 유치원, 어린이집만 학부모들한데 욕바가지 뒤집어쓰는거지.\"',\n",
       " '\"이제 점차 지방으로 확대된다니 실로 걱정되네요 미세먼지가 365일중에 몇일이나 깨끗한지 모를정도로 심한데 그때마다 운행 말라면 당장 차 바꿀 형편 어려운 서민은 어떻게 살죠? 돈이 풍족 하지 못해 서민인데 마치 서민이 죄인같은 세상이네요\"',\n",
       " '\"대부분 중국에서 날라오는데, 중국에는 한마디 못하고 자국민만 패네\"',\n",
       " '\"중국에서 다 처넘어온걸 국민들만 잡냐\"',\n",
       " '\"석탄이나 때지마라\"',\n",
       " '\"참말 골고루한다.하는 짓거리는 유치원생만도 못한 서울시행정 이것이 대한민국 수도이냐 원숭이가 다스리니 오죽하랸.중국에다는 싸대기 맞을까봐 말못하구 없는 서민만 들들들~~~~~들들들\"',\n",
       " '\"운행제한조치해서 공기질 좋아졌다는거 증명해야되는거아니냐??\\\\n그거해서 좋아지는거 없으면 돈없어서 5등급 차 타는 서민 피 빨아먹지마라\"',\n",
       " '\"중국한테 따질건 따지자... 이개  중궈ㅎㄹ세 ㄲ들 때문에 우리가 왜 고통을 ㅂㅏㄷ아야하나\"',\n",
       " '\"불쌍한트럭들만  마녀사냥당하는구나ㅜㅜ\"',\n",
       " '\"세금이26조나더거둬들이더니   돈쓸데가 그리없냐   갑자기  우편물받고  당황햇다  작년말 폐차하려니  조기폐차안되다하여  300백들여 프레임하고  수리다햇더니  이젠폐차하라고???  참나원  서민들을아주개호구로  보는 문정권과박원숭이야..\"',\n",
       " '\"원숭이좀 잡아주세요...\"',\n",
       " '\"백날 그리헤봐라 중국발 미세먼지가 옅어지냐고\"',\n",
       " '\"결국 미세먼지의 주범인 중국에는 끽소리도 못하고, 힘없는  잔챙이에 불과한 국민들만 잡아대네...........무능 독재정권 물러가라!\"',\n",
       " '\"중국한데 따지라고 병진 정부야\"',\n",
       " '\"근본적인 해결을 하세요. 조잡한 정책들로 국민들 힘들어요. 벌금 정책인가?\"',\n",
       " '\"원전폐기정책 재고해야...\\\\n확실하게 안전한 원전으로 미새먼지 없는 나라로.....\"',\n",
       " '\"알았으니 지킬테니까, 어디서 운행못하는 등급인지, 내차는 몇등급인지 쉽게 확인 할 수 있게 해 주세요\"',\n",
       " '\"중국에서 넘어오는걸 왜 자동차를 따져 OOO!! ㄱ 이 볐으니까 생각이 없지!! 니가 ㅁㅅ  한거 사람들이 모르는줄아러? 다 보인다!! 티좀내지말자!! 날씨도 가만히 보면 니가 시른지 이나라에 업씀 공기 무지 좋은데 니가 이씀 공기 무지 나빠지더라?! 그자리에서 내려오는게 우리 국민들을 위한것이고!! 살게하는것이다!! 탄핵!! 탄핵합시다!!\"',\n",
       " '\"5등급차량으로생계유지하는 서울시민은 서울을 떠나살라고하는것 같은국민세금내는데 서울시는  보상을하고 사과하길 미세먼지는 자동차가 주범이아니라고\"',\n",
       " '\"중국은 큰봉우리 작은봉우리 한국은 중국몽과 함께하겟다\"',\n",
       " '\"미세먼지  최대82%  중국을거춰날아와   아주문쟁앙  박원숭이  서민들만  잡아족치는구만  짱개한테는그리관대하더니..\"',\n",
       " '\"문재앙 OOO 이새기는 알고도 시진핑한테 바짝쫄아서 아무말도못함ㅋ.ㅋ\"',\n",
       " '\"미친자들 뙈놈 짱꼴라국에는 찍소리도못하고 돈없고.힘없고.빽없는 서민들만 잡아먹어라 10 샤키들아,\"',\n",
       " '\"매연을 만이배출하는 주범들은 빼고 곁가지만 조져대네ㅜㅜ\\\\n대기업및중소기업들이운영하는공장들 특히 섬유화학공장.용광로를 사용하는 제철및 중공업들 그리고 화력발전소들 예들이 중국다음으로  만은양에 미세먼지를 발생시키는 주범들인데 예들은 쏙빼고 잡범들만 조져대는구나ㅜㅜ\"',\n",
       " '\"왜 2015년을 기준으로 기사를 쓰나요? 2018년 작년 자료가 없나요? 그때의 20프로면 뭐합니까 작년이랑 2015년 미세먼지양이 동급이라고 생각하시나..\"',\n",
       " '\"개돼지들이 지들손으로 뽑은 정부인대 뭘 한탄하는거지 ㅋㅋㅋ 니들이 쳐뽑은 대통령각하님께서 이렇게하라는데 왜 부들대..? ㅎ\"',\n",
       " '\"왜 미세먼지용 마스크 안 쓴 사람도 벌금때리지... 강제하시고...\"',\n",
       " '\"저감장치 달고 싶어도 생산을 안하는 차 브랜드는 어쩌라는건가요ㅡㅡ\"',\n",
       " '\"참내원\\\\n나라를 이꼴로만든건 모두 돈없는 똥차타는사람이구나\"',\n",
       " '\"운송업하시는 분들 어쩌라고...\"',\n",
       " '\"중국이 문제잖아ㅡㅡ이게 뭐하는짓이지?\"',\n",
       " '\"단속만이 만능인가. 환경부담금 돌려다오\"',\n",
       " '\"독재국가냐?\"',\n",
       " '\"그래도 긍정평가가 50프로 넘는데, ㅋㅋ 왜 찍어놓고 그래요.\"',\n",
       " '\"군부독재정권도 아니고 노후차 통행금지라니?\\\\n환경개선부담금은 꼬박꼬박 걷어가면서ㆍ 이건 미세먼지의 주범을 잘못인식한 오판인거같다ㆍ 자동차회사랑 작당한거일수도 있다는 생각도 든다\"',\n",
       " '\"서울만 못하는게 아니라 전국적으로 못하게 해야지. 지방사람들은 뒤져도 되냐?? 원숭이 ㅅㄲ\"',\n",
       " '\"환경부담금  환불해조  박원숭 아\"',\n",
       " '\"세월호 선장 &gt; 문재앙\"',\n",
       " '\"정말 답 없는 정부다...이전 정부도 마찬가지였지만 큰일이네...\"',\n",
       " '\"지가 박정희야 전두환이야 ㅈ까 중국한테는 한마디도 못하면서\"',\n",
       " '\"지방에서 근무하고 있는데 2주일 한번 평균 서울올라가며 제 차량이 렉스턴이라 배축가스 5등급이 나오네요.\\\\n미세 먼지가 언제 심한지 몰라서 1년내내 지방에 있게 생겼네요. 5등급 이하 차량은 강제 폐차를 하던지 이게 무엇하는 짓인지 모르겠네요. 아예 자동차 검사 받을때 문제를 삼던지 해야지 배출가스 검사는 왜하는 것인지...\"',\n",
       " '\"중국에게 할말은 하는 모습을 보여줘야.....(혜안을 가지고, 돌려가면서 옆구리 찌르기 전법 등 구사하여서.....)\\\\n진정한 대한민국의 대통령으로 각인되시기를 바랍니다.\"',\n",
       " '\"트럭들 매연저감장치장착하고다닌지가 20년이 넘였어 요 거기에다가 요즘은 scr저감장치까지 추가로 달고다닌지가 어언 10년이 다되어가요\\\\n뭘좀알고 씹어라 요즘트럭들은 친환경트럭들이란말이다 바부들아 매연들만이 배출하는차는 트럭이 아니라 경유를쓰는 승용차및 suv들이야  얘들은 매연저감장치안단차들이 태반이야   매연저감장치 dpf를 단차량들은 최근 몇년전부터 달았고 dpf보다더 진보된저감장치인 scr은 최근에야 달고나오고있지 dpf하고 scr이두가지 저감장치를 전부달고다니는 차량은 트럭들빼고는 없지\\\\n즉 경유로가는 승용차나 suv가 문제지\"']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List = []\n",
    "\n",
    "url=\"https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=001&aid=0010630211\"\n",
    "\n",
    "oid=url.split(\"oid=\")[1].split(\"&\")[0] \n",
    "aid=url.split(\"aid=\")[1] \n",
    "page=1     \n",
    "header = { \n",
    "    \"User-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36\", \n",
    "    \"referer\":url} \n",
    "\n",
    "while True : \n",
    "    c_url=\"https://apis.naver.com/commentBox/cbox/web_neo_list_jsonp.json?ticket=news&templateId=default_society&pool=cbox5&_callback=jQuery1707138182064460843_1523512042464&lang=ko&country=&objectId=news\"+oid+\"%2C\"+aid+\"&categoryId=&pageSize=20&indexSize=10&groupId=&listType=OBJECT&pageType=more&page=\"+str(page)+\"&refresh=false&sort=FAVORITE\"  \n",
    "# 파싱 단계\n",
    "    r=requests.get(c_url,headers=header) \n",
    "    cont=BeautifulSoup(r.content,\"html.parser\")     \n",
    "    total_comm=str(cont).split('comment\":')[1].split(\",\")[0] \n",
    "   \n",
    "    match=re.findall('\"contents\":([^\\*]*),\"userIdNo\"', str(cont)) \n",
    "# 댓글을 리스트에 중첩\n",
    "    List.append(match) \n",
    "# 한 페이지(댓글 20개 보임)씩 모든 댓글 긁어오기\n",
    "    if int(total_comm) <= ((page) * 20): \n",
    "        break \n",
    "    else :  \n",
    "        page+=1\n",
    "\n",
    "def flatten(l): \n",
    "    flatList = [] \n",
    "    for elem in l: \n",
    "        # if an element of a list is a list \n",
    "        # iterate over this list and add elements to flatList  \n",
    "        if type(elem) == list: \n",
    "            for e in elem: \n",
    "                flatList.append(e) \n",
    "        else: \n",
    "            flatList.append(elem) \n",
    "    return flatList\n",
    "\n",
    "flatten(List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time, random\n",
    "\n",
    "def get_news(n_url):\n",
    "    news_detail = []\n",
    "    print(n_url)\n",
    "    breq = requests.get(n_url)\n",
    "    bsoup = BeautifulSoup(breq.content, 'html.parser')\n",
    "    \n",
    "    # 제목 파싱\n",
    "    title = bsoup.select('h3#articleTitle')[0].text\n",
    "    news_detail.append(title)\n",
    "    \n",
    "    # 날짜\n",
    "    pdate = bsoup.select('.t11')[0].get_test()[:11]\n",
    "    news_detail.append(pdate)\n",
    "    \n",
    "    # news text\n",
    "    _text = bsoup.select('#articleBodyContents')[0].get_text().replace('\\n', \" \")\n",
    "    btext = _text.replace(\"// flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}\", \"\")\n",
    "    news_detail.append(btext.strip())\n",
    "    \n",
    "    # 신문사\n",
    "    pcompany = bsoup.select('#footer address')[0].a.get_text()\n",
    "    news_detail.append(pcompany)\n",
    "    \n",
    "    return news_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "https://search.naver.com/search.naver?where=news&query=김선호배우&sort=1&field=1&ds=2020.01.01&de=2021.04.04&nso=so%3Ar%2Cp%3Afrom20200101to20210404%2Ca%3A&start=1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['날짜','신문사','제목','내용']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "query = '김선호배우'\n",
    "\n",
    "s_date = \"2020.01.01\" \n",
    "\n",
    "e_date = \"2021.04.04\" \n",
    "\n",
    "s_from = s_date.replace(\".\",\"\") \n",
    "\n",
    "e_to = e_date.replace(\".\",\"\") \n",
    "\n",
    "page = 1 \n",
    "\n",
    "while True:\n",
    "    \n",
    "    time.sleep(random.sample(range(3), 1)[0])\n",
    "    print(page) \n",
    "    \n",
    "    url = \"https://search.naver.com/search.naver?where=news&query=\" + query + \"&sort=1&field=1&ds=\" + s_date + \"&de=\" + e_date +\\\n",
    "    \"&nso=so%3Ar%2Cp%3Afrom\" + s_from + \"to\" + e_to + \"%2Ca%3A&start=\" + str(page) \n",
    "\n",
    "\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}    \n",
    "    req = requests.get(url,headers=header) \n",
    "    print(url) \n",
    "\n",
    "    cont = req.content \n",
    "    soup = BeautifulSoup(cont, 'html.parser') \n",
    "\n",
    "\n",
    "    if soup.findAll(\"a\",{\"class\":\"_sp_each_url\"}) == [] :\n",
    "        break \n",
    "\n",
    "    for urls in soup.findAll(\"a\",{\"class\":\"_sp_each_url\"}): \n",
    "        try : \n",
    "            if urls.attrs[\"href\"].startswith(\"https://news.naver.com\"): \n",
    "                print(urls.attrs[\"href\"]) \n",
    "                news_detail = get_news(urls.attrs[\"href\"]) \n",
    "                df=df.append(pd.DataFrame([[news_detail[1], news_detail[3], news_detail[0], news_detail[2]]],columns=columns))\n",
    "\n",
    "        except Exception as e: \n",
    "            print(e)  \n",
    "            continue \n",
    "\n",
    "    page += 10   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 셀레니움을 이용한 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\home\\anaconda3\\lib\\site-packages (3.141.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: urllib3 in c:\\users\\home\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>텍스트</th>\n",
       "      <th>이미지</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>https://scontent-gmp1-1.cdninstagram.com/v/t51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Photo shared by @preference__k on April 03, 20...</td>\n",
       "      <td>https://scontent-gmp1-1.cdninstagram.com/v/t51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>미쳤다 김선호 유죄ㅠㅠㅠㅠ</td>\n",
       "      <td>https://scontent-gmp1-1.cdninstagram.com/v/t51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Photo shared by @preference__k on March 31, 20...</td>\n",
       "      <td>https://scontent-gmp1-1.cdninstagram.com/v/t51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Photo shared by good boi on April 02, 2021 tag...</td>\n",
       "      <td>https://scontent-gmp1-1.cdninstagram.com/v/t51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>Follow us for more updates 🥰\\n#천서진#주단태#오윤희#하윤철...</td>\n",
       "      <td>https://scontent-gmp1-1.cdninstagram.com/v/t51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀\\n#유령을잡아라 메이킹 🎥 \\n오빠 키 짱 커 지...</td>\n",
       "      <td>https://scontent-gmp1-1.cdninstagram.com/v/t51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5070</th>\n",
       "      <td>compilation of kim seonho speaking english #Gl...</td>\n",
       "      <td>https://scontent-gmp1-1.cdninstagram.com/v/t51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5071</th>\n",
       "      <td>.\\n\\n.\\n\\nحلقة ٦٤\\n.\\n.\\n#يومان_وليلة #kim_jon...</td>\n",
       "      <td>https://scontent-gmp1-1.cdninstagram.com/v/t51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>이런 휀이라 미안하지만 기대할게야 ~~~~~~~~ ☺️☺️\\n#김선호 #kimseonho</td>\n",
       "      <td>https://scontent-gmp1-1.cdninstagram.com/v/t51...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1042 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    텍스트  \\\n",
       "0                                                         \n",
       "1     Photo shared by @preference__k on April 03, 20...   \n",
       "2                                        미쳤다 김선호 유죄ㅠㅠㅠㅠ   \n",
       "3     Photo shared by @preference__k on March 31, 20...   \n",
       "4     Photo shared by good boi on April 02, 2021 tag...   \n",
       "...                                                 ...   \n",
       "5068  Follow us for more updates 🥰\\n#천서진#주단태#오윤희#하윤철...   \n",
       "5069  ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀\\n#유령을잡아라 메이킹 🎥 \\n오빠 키 짱 커 지...   \n",
       "5070  compilation of kim seonho speaking english #Gl...   \n",
       "5071  .\\n\\n.\\n\\nحلقة ٦٤\\n.\\n.\\n#يومان_وليلة #kim_jon...   \n",
       "5072  이런 휀이라 미안하지만 기대할게야 ~~~~~~~~ ☺️☺️\\n#김선호 #kimseonho   \n",
       "\n",
       "                                                    이미지  \n",
       "0     https://scontent-gmp1-1.cdninstagram.com/v/t51...  \n",
       "1     https://scontent-gmp1-1.cdninstagram.com/v/t51...  \n",
       "2     https://scontent-gmp1-1.cdninstagram.com/v/t51...  \n",
       "3     https://scontent-gmp1-1.cdninstagram.com/v/t51...  \n",
       "4     https://scontent-gmp1-1.cdninstagram.com/v/t51...  \n",
       "...                                                 ...  \n",
       "5068  https://scontent-gmp1-1.cdninstagram.com/v/t51...  \n",
       "5069  https://scontent-gmp1-1.cdninstagram.com/v/t51...  \n",
       "5070  https://scontent-gmp1-1.cdninstagram.com/v/t51...  \n",
       "5071  https://scontent-gmp1-1.cdninstagram.com/v/t51...  \n",
       "5072  https://scontent-gmp1-1.cdninstagram.com/v/t51...  \n",
       "\n",
       "[1042 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd \n",
    "\n",
    "driver = webdriver.Chrome('C:/Users/HOME/Documents/python/chromedriver.exe')\n",
    "\n",
    "driver.get(\"https://www.instagram.com/explore/tags/김선호/?hl=ko\")\n",
    "\n",
    "text=[]\n",
    "image=[]\n",
    "for i in range(100):\n",
    "    html = driver.page_source\n",
    "    soup=BeautifulSoup(html,'html.parser')\n",
    "    List=soup.find_all(\"img\")\n",
    "    for j in range(len(List)):\n",
    "        if (soup.find_all(\"img\")[j]).has_attr('alt') and (soup.find_all(\"img\")[j]).has_attr('src'):\n",
    "            text.append(List[j]['alt'])\n",
    "            image.append(List[j]['src'])\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "\n",
    "df=(pd.DataFrame(list(zip(text, image)),columns=[\"텍스트\",\"이미지\"]))\n",
    "df2=(df.drop_duplicates(['텍스트','이미지'], keep='first'))\n",
    "final=df2\n",
    "\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"#yui_3_16_0_1_1617546615995_479\"]\"}\n  (Session info: chrome=89.0.4389.114)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-cffd2731eaa2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"서울 야경\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#yui_3_16_0_1_1617546615995_479\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"search-field\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENTER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_id\u001b[1;34m(self, id_)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'foo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \"\"\"\n\u001b[1;32m--> 360\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"#yui_3_16_0_1_1617546615995_479\"]\"}\n  (Session info: chrome=89.0.4389.114)\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('C:/Users/HOME/Documents/python/chromedriver.exe') \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "base_url = 'https://www.flickr.com/'\n",
    "driver.get(base_url)\n",
    "\n",
    "query=\"서울 야경\"\n",
    "\n",
    "driver.find_element_by_id(\"search-field\").send_keys(query)\n",
    "driver.find_element_by_id(\"search-field\").send_keys(Keys.ENTER)\n",
    "time.sleep(3)\n",
    "\n",
    "list_size_pre=0\n",
    "list_size=0\n",
    "while True:\n",
    "    list_size_pre=list_size\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(3)\n",
    "    url_list=driver.find_elements_by_class_name(\"overlay\")\n",
    "    list_size=len(url_list)\n",
    "    if list_size == list_size_pre:\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//*[contains(text(), '결과 자세히 알아보기')]\").click()\n",
    "        except Exception as e:\n",
    "            break\n",
    "\n",
    "url_list=driver.find_elements_by_class_name(\"overlay\")\n",
    "url_list2=[]\n",
    "for i in url_list:\n",
    "    url_list2.append(i.get_attribute(\"href\"))\n",
    "\n",
    "driver2 = webdriver.Chrome('C:/Users/user1/Downloads/chromedriver_win32/chromedriver.exe')\n",
    "\n",
    "image=[]\n",
    "tag=[]\n",
    "comments=[]\n",
    "\n",
    "for i in range(len(url_list2)):\n",
    "    try:\n",
    "        driver2.get(url_list2[i])\n",
    "        driver2.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        html = driver2.page_source\n",
    "        soup=BeautifulSoup(html,'html.parser')\n",
    "        image.append(soup.find_all(\"img\",{\"class\":\"main-photo\"})[0]['src'])\n",
    "        time.sleep(3)\n",
    "        if driver2.find_elements_by_class_name(\"tags-list\") != []:\n",
    "            tag.append((driver2.find_element_by_class_name(\"tags-list\").text).replace(\"\\n\",\",\"))\n",
    "        else:\n",
    "            tag.append(\" \")\n",
    "        if driver2.find_elements_by_class_name(\"comments\") != []:\n",
    "            comments.append((driver2.find_element_by_class_name(\"comments\").text).replace(\"\\n\",\",\"))\n",
    "        else:\n",
    "            comments.append(\"\")\n",
    "        if i % 10 == 0:\n",
    "            print(str(i)+\"번째 완료\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
